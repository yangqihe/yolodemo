
import os
import queue
import json
import sounddevice as sd
import pyttsx3
import numpy as np
import joblib
from sentence_transformers import SentenceTransformer
from vosk import Model, KaldiRecognizer
from sklearn.metrics.pairwise import cosine_similarity

from sbert.sbert_const import local_huggingface_path

# åŠ è½½ Vosk ä¸­æ–‡æ¨¡å‹
vosk_model_path = "../model/vosk/vosk-model-cn-0.22"
print("åˆ¤æ–­æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
if not os.path.exists(vosk_model_path):
    raise FileNotFoundError("ç¼ºå°‘ Vosk ä¸­æ–‡æ¨¡å‹ï¼Œè¯·ä¸‹è½½è§£å‹åæ”¾ç½®åœ¨å½“å‰ç›®å½•")

print("ğŸ”„ æ­£åœ¨åŠ è½½ Vosk æ¨¡å‹...")
rec = KaldiRecognizer(Model(vosk_model_path), 16000)
print("âœ… Vosk æ¨¡å‹åŠ è½½å®Œæˆ")
q = queue.Queue()

print("ğŸ”„ æ­£åœ¨åŠ è½½ SBERT æ¨¡å‹...")
# åŠ è½½ SBERT å‘é‡æ¨¡å‹å’Œæ¨¡æ¿ç´¢å¼•
sbert_index = joblib.load("sbert_intent/intent_sbert_index.pkl")
#sbert_model = SentenceTransformer(sbert_index["model_name"])
sbert_model = SentenceTransformer(local_huggingface_path, local_files_only=True)
print("âœ… SBERT æ¨¡å‹åŠ è½½å®Œæˆ")
index_vecs = sbert_index["embeddings"]
index_labels = sbert_index["labels"]
index_texts = sbert_index["texts"]

# æ§åˆ¶åŠ¨ä½œæ‰§è¡Œæ¨¡æ‹Ÿï¼ˆä»…æ‰“å°ï¼‰
def execute_action(action):
    print(f"ğŸ¦¾ æ‰§è¡ŒåŠ¨ä½œï¼š{action}")
    engine.say(f"æ‰§è¡Œ {action}")
    engine.runAndWait()

# ç®€æ´èŠå¤©å›å¤
def short_reply(text):
    if "ä½ æ˜¯è°" in text:
        return "æˆ‘æ˜¯è¯­éŸ³åŠ©æ‰‹"
    elif "å¤©æ°”" in text:
        return "æˆ‘ä¸æŸ¥å¤©æ°”"
    elif "ä½ å¥½" in text:
        return "ä½ å¥½ï¼"
    else:
        return "ä½ è¯´çš„æ˜¯ï¼š" + text[:10]

# æ¨ç†å‡½æ•°
def predict_intent(text, threshold=0.6):
    vec = sbert_model.encode([text])
    sims = cosine_similarity(vec, index_vecs)[0]
    best_idx = np.argmax(sims)
    best_score = sims[best_idx]
    best_label = index_labels[best_idx]
    best_template = index_texts[best_idx]
    if best_score < threshold:
        return "chat", best_score, best_template
    return best_label, best_score, best_template

# éŸ³é¢‘æµè¾“å…¥
def callback(indata, frames, time, status):
    q.put(bytes(indata))

# æ’­æŠ¥å¼•æ“
engine = pyttsx3.init()
engine.setProperty("rate", 160)
engine.setProperty("volume", 1.0)

def main():
    print("ğŸ¤ å¯åŠ¨ Vosk + SBERT è¯­éŸ³æ„å›¾è¯†åˆ«ç³»ç»Ÿ...")
    with sd.RawInputStream(device=1, samplerate=16000, blocksize=8000, dtype='int16',
                           channels=1, callback=callback):
        last_partial = ""
        while True:
            data = q.get()
            if rec.AcceptWaveform(data):
                result = json.loads(rec.Result())
                text = result.get("text", "")
                if text:
                    print("\nâœ… æœ€ç»ˆè¯†åˆ«ç»“æœï¼š", text)
                    if len(text) == 1:
                        print("ğŸ’¬ å¤ªçŸ­ï¼š", text)
                        return
                    label, score, matched = predict_intent(text)
                    print(f"ğŸ¯ è¯†åˆ«æ„å›¾ï¼š{label}ï¼ˆç½®ä¿¡åº¦ï¼š{score:.2f}ï¼‰ â† åŒ¹é…ï¼š{matched}")
                    if label == "chat":
                        reply = short_reply(text)
                        print("ğŸ’¬ å›å¤ï¼š", reply)
                        engine.say(reply)
                        engine.runAndWait()
                    else:
                        execute_action(label)
                    last_partial = ""
            else:
                partial = json.loads(rec.PartialResult())
                ptext = partial.get("partial", "")
                if ptext and ptext != last_partial:
                    print("ğŸ•“ ä¸´æ—¶è¯†åˆ«ï¼š", ptext)
                    last_partial = ptext

if __name__ == "__main__":
    main()
