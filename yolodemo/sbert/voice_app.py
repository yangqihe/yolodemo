import os
import queue
import json
import threading
import numpy as np
import sounddevice as sd
import pyttsx3
import joblib
from PyQt5.QtWidgets import (
    QApplication, QWidget, QPushButton, QTextEdit, QVBoxLayout, QLabel, QDesktopWidget
)
from PyQt5.QtCore import Qt
from sentence_transformers import SentenceTransformer
from vosk import Model, KaldiRecognizer
from sklearn.metrics.pairwise import cosine_similarity

from sbert.sbert_const import intent_to_natural_reply

q = queue.Queue()
is_listening = False
rec = None


# âœ… åŠ è½½æ¨¡å‹
vosk_model_path = "../../model/vosk/vosk-model-cn-0.22"
if not os.path.exists(vosk_model_path):
    raise FileNotFoundError("âŒ ç¼ºå°‘ Vosk ä¸­æ–‡æ¨¡å‹ï¼Œè¯·ä¸‹è½½è§£å‹åæ”¾ç½®åœ¨å½“å‰ç›®å½•")
rec = KaldiRecognizer(Model(vosk_model_path), 16000)

sbert_index = joblib.load("sbert_intent/intent_sbert_index.pkl")
sbert_model = SentenceTransformer(sbert_index["model_name"])
index_vecs = sbert_index["embeddings"]
index_labels = sbert_index["labels"]
index_texts = sbert_index["texts"]

engine = pyttsx3.init()
engine.setProperty("rate", 160)
engine.setProperty("volume", 1.0)

def short_reply(text):
    if "ä½ æ˜¯è°" in text:
        return "æˆ‘æ˜¯è¯­éŸ³åŠ©æ‰‹"
    elif "å¤©æ°”" in text:
        return "æˆ‘ä¸æŸ¥å¤©æ°”"
    elif "ä½ å¥½" in text:
        return "ä½ å¥½ï¼Œæˆ‘æ˜¯å·¥åŠå°åŠ©æ‰‹"
    else:
        return "æˆ‘ä¼šæ—‹è½¬æœºæ¢°è‡‚ï¼Œä¼šæ‹ç…§ï¼Œè¿˜ä¼šæµ‹é‡PHå’Œæº¶æ°§ï¼Œä½ è®©æˆ‘åšä»€ä¹ˆå‘¢ï¼Ÿ"
        #return "ä½ è¯´çš„æ˜¯ï¼š" + text[:10]

def predict_intent(text, threshold=0.6):
    vec = sbert_model.encode([text])
    sims = cosine_similarity(vec, index_vecs)[0]
    best_idx = np.argmax(sims)
    best_score = sims[best_idx]
    best_label = index_labels[best_idx]
    best_template = index_texts[best_idx]
    if best_score < threshold:
        return "chat", best_score, best_template
    return best_label, best_score, best_template

def execute_action(action):
    print(f"ğŸ¦¾ æ‰§è¡ŒåŠ¨ä½œï¼š{action}")
    engine.say(f"æ‰§è¡Œ {action}")
    engine.runAndWait()

def audio_callback(indata, frames, time, status):
    if is_listening:
        q.put(bytes(indata))

class VoiceApp(QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("è¯­éŸ³åŠ©æ‰‹")
        self.resize(1000, 800)
        self.center_window()

        # æ˜¾ç¤ºä¸´æ—¶è¯†åˆ«ï¼ˆå­—ä½“å¤§ä¸€äº›ï¼‰
        self.partial_label = QLabel("", self)
        self.partial_label.setStyleSheet("color: gray; font-size: 18px; font-style: italic;")

        self.text_display = QTextEdit(self)
        self.text_display.setReadOnly(True)
        self.text_display.setStyleSheet("font-size: 16px;")

        self.button = QPushButton("ğŸ™ï¸ å¼€å§‹", self)
        self.button.setStyleSheet("font-size: 16px;")
        self.button.clicked.connect(self.toggle_recognition)

        layout = QVBoxLayout()
        layout.addWidget(self.partial_label)
        layout.addWidget(self.text_display)
        layout.addWidget(self.button)
        self.setLayout(layout)

        self.stream = sd.RawInputStream(device=None, samplerate=16000, blocksize=8000,
                                        dtype='int16', channels=1, callback=audio_callback)

    def center_window(self):
        screen = QDesktopWidget().screenGeometry()
        size = self.geometry()
        self.move((screen.width() - size.width()) // 2,
                  (screen.height() - size.height()) // 2)

    def toggle_recognition(self):
        global is_listening
        if not is_listening:
            self.text_display.clear()
            self.partial_label.setText("")
            self.button.setText("â¹ï¸ åœæ­¢")
            is_listening = True
            self.stream.start()
            threading.Thread(target=self.recognition_loop, daemon=True).start()
        else:
            is_listening = False
            self.button.setText("ğŸ™ï¸ å¼€å§‹")
            self.stream.stop()

            # âœ… ä¿ç•™æ¸…é™¤é€»è¾‘
            while not q.empty():
                try:
                    q.get_nowait()
                except queue.Empty:
                    break

            try:
                final_result = json.loads(rec.FinalResult())
                text = final_result.get("text", "").strip()
                if text:
                    self.text_display.append(f"\nâœ… æœ€ç»ˆè¯†åˆ«ç»“æœï¼š{text}")
                    label, score, matched = predict_intent(text)
                    self.text_display.append(f"ğŸ¯ æ„å›¾ï¼š{label}ï¼ˆç½®ä¿¡åº¦ï¼š{score:.2f}ï¼‰")
                    if label == "chat":
                        reply = short_reply(text)
                        self.text_display.append(f"ğŸ’¬ å›å¤ï¼š{reply}")
                        engine.say(reply)
                        engine.runAndWait()
                    else:
                        reply_text = intent_to_natural_reply.get(label, matched)
                        friendly_reply = f"å¥½çš„ï¼Œæˆ‘é©¬ä¸Š{reply_text}"
                        self.text_display.append(f"ğŸ’¬ å›å¤ï¼š{friendly_reply}")
                        engine.say(friendly_reply)
                        engine.runAndWait()
                        execute_action(label)
            except Exception as e:
                self.text_display.append(f"âš ï¸ å°¾éŸ³è¯†åˆ«å¤±è´¥ï¼š{e}")

    def recognition_loop(self):
        last_partial = ""
        while is_listening:
            try:
                data = q.get(timeout=1)
            except queue.Empty:
                continue
            if rec.AcceptWaveform(data):
                result = json.loads(rec.Result())
                text = result.get("text", "").strip()
                self.partial_label.setText("")
                if not text or len(text) < 2:
                    continue
                self.text_display.append(f"\nâœ… æœ€ç»ˆè¯†åˆ«ç»“æœï¼š{text}")
                label, score, matched = predict_intent(text)
                self.text_display.append(f"ğŸ¯ æ„å›¾ï¼š{label}ï¼ˆç½®ä¿¡åº¦ï¼š{score:.2f}ï¼‰")
                if label == "chat":
                    reply = short_reply(text)
                    self.text_display.append(f"ğŸ’¬ å›å¤ï¼š{reply}")
                    engine.say(reply)
                    engine.runAndWait()
                else:
                    reply_text = intent_to_natural_reply.get(label, matched)
                    friendly_reply = f"å¥½çš„ï¼Œæˆ‘é©¬ä¸Š{reply_text}"
                    self.text_display.append(f"ğŸ’¬ å›å¤ï¼š{friendly_reply}")
                    engine.say(friendly_reply)
                    engine.runAndWait()
                    execute_action(label)
            else:
                partial = json.loads(rec.PartialResult())
                ptext = partial.get("partial", "")
                if ptext and ptext != last_partial:
                    self.partial_label.setText(f"ğŸ•“ å½“å‰è¯†åˆ«ï¼š{ptext}")
                    last_partial = ptext

if __name__ == "__main__":
    import sys
    app = QApplication(sys.argv)
    window = VoiceApp()
    window.show()
    sys.exit(app.exec_())
