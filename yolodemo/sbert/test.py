# import sounddevice as sd
# import soundfile as sf
# import whisper
# import numpy as np
#
# def record_audio(duration=3, samplerate=16000, filename="temp.wav"):
#     print("ðŸŽ™ï¸ å¼€å§‹å½•éŸ³ 3 ç§’...")
#     data = sd.rec(int(samplerate * duration), samplerate=samplerate, channels=1, dtype='int16')
#     sd.wait()
#     sf.write(filename, data, samplerate)
#     print(f"âœ… å½•éŸ³ä¿å­˜ä¸º {filename}")
#     print(f"ðŸŽšï¸ æœ€å¤§æŒ¯å¹…: {np.max(np.abs(data))}")
#     return filename
#
# def recognize_with_whisper(filename):
#     print("ðŸ” åŠ è½½ Whisper æ¨¡åž‹...")
#     model = whisper.load_model("medium")  # or "small", "medium", "large"
#     print("ðŸ“¥ å¼€å§‹è¯†åˆ«...")
#     result = model.transcribe(filename, language="zh")
#     print("ðŸ“ è¯†åˆ«ç»“æžœï¼š", result['text'])
#
# if __name__ == "__main__":
#     path = record_audio()
#     recognize_with_whisper(path)


# from sentence_transformers import SentenceTransformer
#
# from sbert.sbert_const import local_model_path
#
# model = SentenceTransformer(
#     local_model_path,
#     local_files_only=True
# )
# print("âœ… æœ¬åœ°æ¨¡åž‹åŠ è½½æˆåŠŸ")


# import whisper
# model = whisper.load_model("medium").to("cuda")
# # True è¡¨ç¤º GPU å¯ç”¨


import difflib
from pypinyin import lazy_pinyin

# control_templates = {
#     "extend_arm": ["æ‰“å¼€æœºæ¢°è‡‚", "ä¼¸å‡ºæœºæ¢°è‡‚"],
#     "retract_arm": ["æ”¶å›žæœºæ¢°è‡‚", "å…³é—­æœºæ¢°è‡‚"],
#     "open_camera": ["æ‰“å¼€ç›¸æœº", "å¯åŠ¨æ‘„åƒå¤´"],
#     # å¯ç»§ç»­è¡¥å……ä½ çš„æŒ‡ä»¤
# }

# def get_best_pinyin_match(input_text, templates, threshold=0.6):
#     input_pinyin = lazy_pinyin(input_text)
#     best_match = None
#     best_score = 0.0
#
#     for template in templates:
#         template_pinyin = lazy_pinyin(template)
#         matcher = difflib.SequenceMatcher(None, input_pinyin, template_pinyin)
#         score = matcher.ratio()
#         if score > best_score:
#             best_match = template
#             best_score = score
#
#     return (best_match, best_score) if best_score >= threshold else (input_text, best_score)
#
# # æ‰å¹³åŒ–æ¨¡æ¿
# all_templates = [phrase for phrases in control_templates.values() for phrase in phrases]
#
# # æµ‹è¯•æ ·ä¾‹
# inputs = ["æ‰“å¼€æœºæ¢°å£", "æ”¶å›žæœºæ¢°å¸", "æ‰“é–‹ç›¸æ©Ÿ"]
# for text in inputs:
#     corrected, score = get_best_pinyin_match(text, all_templates)
#     print(f"åŽŸå¥: {text} => çº æ­£: {corrected}ï¼ˆç›¸ä¼¼åº¦: {score:.2f}ï¼‰")


import torch
print(torch.__version__)
print(torch.version.cuda)
print(torch.backends.cudnn.is_available())