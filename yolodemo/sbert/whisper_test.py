import sys
import time
import numpy as np
import sounddevice as sd
import soundfile as sf
import whisper

from PyQt5.QtWidgets import (
    QApplication, QWidget, QVBoxLayout, QPushButton, QLabel, QTextEdit
)
from PyQt5.QtCore import Qt, QTimer


class WhisperGUI(QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Whisper ä¸­æ–‡è¯­éŸ³è¯†åˆ«")
        self.setGeometry(400, 200, 500, 300)
        self.model = None

        self.init_ui()
        self.load_model_async()

    def init_ui(self):
        layout = QVBoxLayout()

        self.status_label = QLabel("æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹...")
        self.status_label.setAlignment(Qt.AlignCenter)
        layout.addWidget(self.status_label)

        self.record_button = QPushButton("ğŸ™ï¸ å¼€å§‹å½•éŸ³å¹¶è¯†åˆ«")
        self.record_button.setEnabled(False)
        self.record_button.clicked.connect(self.record_and_recognize)
        layout.addWidget(self.record_button)

        self.result_text = QTextEdit()
        self.result_text.setReadOnly(True)
        layout.addWidget(self.result_text)

        self.setLayout(layout)

    def load_model_async(self):
        # åŠ è½½æ¨¡å‹ï¼ˆå¼‚æ­¥æ„ŸçŸ¥ç”¨æˆ·ï¼‰
        QTimer.singleShot(500, self.load_model)

    def load_model(self):
        self.model = whisper.load_model("medium")
        self.status_label.setText("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œå¯ä»¥å¼€å§‹å½•éŸ³")
        self.record_button.setEnabled(True)

    def record_with_countdown(self, duration=3, samplerate=16000, filename="temp.wav"):
        self.status_label.setText(f"ğŸ™ï¸ æ­£åœ¨å½•éŸ³ï¼ˆ{duration}ç§’ï¼‰...")
        QApplication.processEvents()

        # å¼€å§‹å½•éŸ³
        audio = sd.rec(int(samplerate * duration), samplerate=samplerate, channels=1, dtype='int16')

        # å€’è®¡æ—¶æç¤º
        for i in range(duration, 0, -1):
            self.status_label.setText(f"ğŸ™ï¸ æ­£åœ¨å½•éŸ³ï¼ˆå‰©ä½™ {i} ç§’ï¼‰...")
            QApplication.processEvents()
            time.sleep(1)

        # ç­‰å¾…å½•éŸ³å®Œæˆ
        sd.wait()
        sf.write(filename, audio, samplerate)
        max_amp = np.max(np.abs(audio))

        return filename, max_amp

    def record_and_recognize(self):
        self.result_text.setText('')

        self.record_button.setEnabled(False)

        filename, max_amp = self.record_with_countdown()
        self.status_label.setText(f"âœ… å½•éŸ³å®Œæˆï¼Œæœ€å¤§æŒ¯å¹…: {max_amp}")
        QApplication.processEvents()

        # å¼€å§‹è¯†åˆ«
        self.status_label.setText("ğŸ§  æ­£åœ¨è¯†åˆ«ä¸­...")
        QApplication.processEvents()

        result = self.model.transcribe(filename, language="zh")
        self.result_text.setText(result['text'])

        self.status_label.setText("âœ… è¯†åˆ«å®Œæˆ")
        self.record_button.setEnabled(True)


if __name__ == "__main__":
    app = QApplication(sys.argv)
    window = WhisperGUI()
    window.show()
    sys.exit(app.exec_())
