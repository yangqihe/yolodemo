
import os
import queue
import json
import re
import sounddevice as sd
from vosk import Model, KaldiRecognizer

# æ¨¡å‹è·¯å¾„
model_path = "vosk-model-small-cn-0.22"
if not os.path.exists(model_path):
    raise FileNotFoundError("è¯·ä¸‹è½½ä¸­æ–‡æ¨¡å‹ vosk-model-small-cn-0.22 å¹¶æ”¾åˆ°è„šæœ¬ç›®å½•ä¸‹")

# åˆå§‹åŒ–
model = Model(model_path)
rec = KaldiRecognizer(model, 16000)
q = queue.Queue()

# éŸ³é¢‘è¾“å…¥è®¾å¤‡ IDï¼ˆå¯æ ¹æ®ç³»ç»Ÿè°ƒæ•´ï¼‰
device_id = 1

# åˆ†å¥å‡½æ•°
def split_sentences(text):
    sents = re.split(r'(ã€‚|ï¼|\!|ï¼Ÿ|\?)', text)
    results = []
    for i in range(0, len(sents) - 1, 2):
        results.append(sents[i] + sents[i + 1])
    if len(sents) % 2 == 1:
        results.append(sents[-1])
    return results

# å›è°ƒå‡½æ•°
def callback(indata, frames, time, status):
    q.put(bytes(indata))

# ä¸»è¯­éŸ³è¯†åˆ«å¾ªç¯
def run():
    print("ğŸ™ï¸ è¯­éŸ³è¯†åˆ«å¼€å§‹ï¼Œè¯·è®²è¯...")
    with sd.RawInputStream(device=device_id, samplerate=16000, blocksize=8000, dtype='int16',
                           channels=1, callback=callback):
        while True:
            data = q.get()
            if rec.AcceptWaveform(data):
                result = json.loads(rec.Result())
                final_text = result.get("text", "")
                if final_text:
                    print("âœ… æœ€ç»ˆè¯†åˆ«ï¼š")
                    for line in split_sentences(final_text):
                        print("â¤", line)
            else:
                partial = json.loads(rec.PartialResult())
                partial_text = partial.get("partial", "")
                if partial_text:
                    print("ğŸ•“ ä¸´æ—¶ï¼š", partial_text, end="\r")

if __name__ == "__main__":
    run()
